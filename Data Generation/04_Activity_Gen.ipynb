{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO24LabP4hzrtZ3sFootuCH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**1) Environment Setup, Install, and Load Dependencies**\n","\n","\n","Cell re-establishes the environment, installs the necessary package, and loads all the crucial foreign key IDs needed to link the final activity records (listings, appointments, transactions, etc.) back to Agents, Clients, and Properties."],"metadata":{"id":"eQN2zF6pv6Xe"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTj_m54Mvt8Q","executionInfo":{"status":"ok","timestamp":1763098123445,"user_tz":480,"elapsed":27375,"user":{"displayName":"Maya Patel","userId":"14782061383850637760"}},"outputId":"16200bb0-f360-4824-b8b9-c9fe952a8e38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faker\n","  Downloading faker-38.0.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n","Downloading faker-38.0.0-py3-none-any.whl (2.0 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m137.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faker\n","Successfully installed faker-38.0.0\n","Mounted at /content/drive\n"]}],"source":["### 1. Setup, Imports, and Load Foreign Key IDs ###\n","\n","# Reinstall Faker as the environment resets in a new notebook\n","%pip install faker\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import csv\n","import random\n","import json\n","import os\n","from datetime import datetime, timedelta\n","from faker import Faker\n","\n","# --- CONFIGURATION (Must match preceding Notebooks) ---\n","fake = Faker()\n","Faker.seed(42)\n","random.seed(42)\n","\n","# Set the OUTPUT DIRECTORY (MUST match your path)\n","output_dir = '/content/drive/MyDrive/SQL Project (Group 2)/Simulating Data (Maya)/Simulated Data Files'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# --- Data Utility Functions ---\n","\n","def load_ids(filename):\n","    \"\"\"Loads a single column of integer IDs from a specified CSV file.\"\"\"\n","    ids = []\n","    filepath = os.path.join(output_dir, filename)\n","    try:\n","        with open(filepath, 'r', newline='') as file:\n","            reader = csv.reader(file)\n","            next(reader)  # Skip header\n","            for row in reader:\n","                ids.append(int(row[0]))\n","    except FileNotFoundError:\n","        print(f\"Error: {filename} not found. Please ensure preceding notebooks were run.\")\n","    return ids\n","\n","def write_csv(filename, headers, data_rows):\n","    \"\"\"Writes data to a CSV file, converting empty strings to None.\"\"\"\n","    filepath = os.path.join(output_dir, filename)\n","    with open(filepath, 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow(headers)\n","        clean_rows = [[(val if val != '' else None) for val in row] for row in data_rows]\n","        writer.writerows(clean_rows)\n","\n","# --- Load Necessary Foreign Keys ---\n","agent_ids = load_ids('agent_ids.csv')\n","client_ids = load_ids('client_ids.csv')\n","property_ids = load_ids('property_ids.csv')\n","listing_ids = list(range(1, 101))"]},{"cell_type":"markdown","source":["**2) Generate Transactional and Activity Data**\n","\n","Generates all activity-based tables: **Listings** (Level 5), and the six subsequent **Transactional Tables** (Level 6).\n","\n","* **Listings (Fixed Logic):** The code now correctly bounds the `closed_date` to prevent the \"empty range\" error while ensuring the closing date is always after the listing date.\n","* **Transactions:** The `transactions` table omits `office_id` in the CSV, relying on your PostgreSQL trigger to populate it automatically."],"metadata":{"id":"bYJ0HLo_wLxV"}},{"cell_type":"markdown","source":["**3) Generate Listings and Activities**\n","\n","\n","Cell executes the logic to generate the remaining five tables and saves the CSVs."],"metadata":{"id":"R-SDkMXhwaVW"}},{"cell_type":"code","source":["### Generate Listings and Activities ###\n","\n","# --- 8. Generate Listings (100) ---\n","listings = []\n","for i in range(100):\n","    property_id = property_ids[i]\n","    agent_id = random.choice(agent_ids)\n","    list_price = round(random.uniform(300000, 3000000), 2)\n","\n","    status_id = random.choices([1, 2, 3, 4, 5], weights=[40, 10, 35, 10, 5])[0]\n","\n","    closed_date = ''\n","\n","    if status_id in [3, 4]: # Status is Sold (3) or Rented (4)\n","        # 1. Generate the guaranteed closed date (max date is today)\n","        closed_date_obj = fake.date_between(start_date='-1y', end_date='today')\n","        closed_date = closed_date_obj.strftime('%Y-%m-%d')\n","\n","        # 2. Set the cap for the listed date to 1 day before closing\n","        max_listed_date_obj = closed_date_obj - timedelta(days=1)\n","\n","        # 3. Set the absolute minimum historical date (2 years ago)\n","        min_listed_date = datetime.now().date() - timedelta(days=365 * 2)\n","\n","        # Generate listed date within the chronologically valid range\n","        if max_listed_date_obj < min_listed_date:\n","            # If the closing date is ancient, use the closing date minus 1 day as the listed date\n","            listed_date_obj = max_listed_date_obj\n","        else:\n","            # Generate random date between historical start and the closing cap.\n","            listed_date_obj = fake.date_between(start_date=min_listed_date, end_date=max_listed_date_obj)\n","\n","        listed_date = listed_date_obj.strftime('%Y-%m-%d')\n","\n","    else: # Active, Pending, Withdrawn (status_id 1, 2, 5) - no chronological constraint conflict\n","        listed_date_obj = fake.date_between(start_date='-2y', end_date='today')\n","        listed_date = listed_date_obj.strftime('%Y-%m-%d')\n","\n","    listings.append([i+1, property_id, agent_id, list_price, status_id, listed_date, closed_date])\n","\n","write_csv('listings.csv',\n","    ['listing_id', 'property_id', 'agent_id', 'list_price', 'listing_status_id', 'listed_date', 'closed_date'],\n","    listings)\n","\n","\n","# --- 9. Generate Appointments (100) ---\n","appointments = []\n","for i in range(100):\n","    appt_type = random.randint(1, 4)\n","    appt_datetime = fake.date_time_between(start_date='-6m', end_date='now').strftime('%Y-%m-%d %H:%M:%S')\n","    listing_id = random.choice(listing_ids)\n","    client_id = random.choice(client_ids)\n","    outcome_id = random.randint(1, 4) if random.random() < 0.8 else ''\n","    notes_options_by_outcome = {\n","        1: \"Client attended, gathering feedback.\", 2: \"No show, attempting to reschedule.\",\n","        3: \"Client loved the property, drafting an offer.\", 4: \"Requires follow-up on financing.\",\n","        '': \"Outcome pending or appointment not yet complete.\"\n","    }\n","    notes = notes_options_by_outcome.get(outcome_id, notes_options_by_outcome[''])\n","\n","    appointments.append([i+1, appt_type, appt_datetime, listing_id, client_id, outcome_id, notes])\n","\n","write_csv('appointments.csv',\n","    ['appointment_id', 'appointment_type_id', 'appointment_datetime', 'listing_id', 'client_id',\n","     'appointment_outcome_id', 'notes'],\n","    appointments)\n","\n","\n","# --- 10. Generate Offers (120) ---\n","offers = []\n","for i in range(120):\n","    listing_id = random.choice(listing_ids)\n","    buyer_client_id = random.choice(client_ids)\n","    base_price = random.uniform(300000, 3000000)\n","    offer_amount = round(base_price * random.uniform(0.90, 1.05), 2)\n","    offer_date = fake.date_between(start_date='-1y', end_date='today').strftime('%Y-%m-%d')\n","    status_id = random.choices([1, 2, 3, 4, 5, 6], weights=[20, 25, 30, 10, 10, 5])[0]\n","    notes = random.choice([\"Competitive offer with quick closing\", \"Subject to financing approval\", \"All cash offer\", \"Contingent on selling current home\", ''])\n","\n","    offers.append([i+1, listing_id, buyer_client_id, offer_amount, offer_date, status_id, notes])\n","\n","write_csv('offers.csv',\n","    ['offer_id', 'listing_id', 'buyer_client_id', 'offer_amount', 'offer_date', 'offer_status_id', 'notes'],\n","    offers)\n","\n","\n","# --- 11. Generate Transactions (100) ---\n","transactions = []\n","for i in range(100):\n","    listing_id = listing_ids[i]\n","    buyer_client_id = random.choice(client_ids)\n","    seller_client_id = random.choice(client_ids)\n","    agent_id = random.choice(agent_ids)\n","    tx_type = random.choices(['Sale', 'Rental'], weights=[80, 20])[0]\n","\n","    close_price = round(random.uniform(300000, 3000000), 2) if tx_type == 'Sale' else round(random.uniform(1500, 8000), 2)\n","    commission_pct = random.uniform(0.02, 0.06)\n","    commission_amount = round(close_price * commission_pct, 2)\n","    close_date = fake.date_between(start_date='-1y', end_date='today').strftime('%Y-%m-%d')\n","\n","    transactions.append([i+1, listing_id, buyer_client_id, seller_client_id, agent_id,\n","                        tx_type, close_price, round(commission_pct, 4), commission_amount, close_date])\n","\n","write_csv('transactions.csv',\n","    ['transaction_id', 'listing_id', 'buyer_client_id', 'seller_client_id', 'agent_id',\n","     'transaction_type', 'close_price', 'commission_pct', 'commission_amount', 'close_date'],\n","    transactions)\n","\n","\n","# --- 12. Generate Marketing Campaigns (150) ---\n","campaigns = []\n","channels = ['website', 'social media', 'email', 'print', '3rd-party portal']\n","\n","for i in range(150):\n","    listing_id = random.choice(listing_ids)\n","    channel = random.choice(channels)\n","    start_date = fake.date_between(start_date='-1y', end_date='today').strftime('%Y-%m-%d')\n","\n","    end_date = ''\n","    if random.random() < 0.7:\n","        min_end_date = datetime.strptime(start_date, '%Y-%m-%d').date() + timedelta(days=1)\n","        max_end_date = datetime.now().date()\n","\n","        if min_end_date <= max_end_date:\n","            end_date_obj = fake.date_between(start_date=min_end_date, end_date=max_end_date)\n","            end_date = end_date_obj.strftime('%Y-%m-%d')\n","\n","    cost = round(random.uniform(100, 5000), 2)\n","    impressions = random.randint(1000, 100000)\n","    clicks = random.randint(10, int(impressions * 0.05))\n","\n","    campaigns.append([i+1, listing_id, channel, start_date, end_date, cost, impressions, clicks])\n","\n","write_csv('marketing_campaigns.csv',\n","    ['marketing_campaign_id', 'listing_id', 'channel', 'start_date', 'end_date', 'cost', 'impressions', 'clicks'],\n","    campaigns)\n","\n","print(\"SUCCESS: All temporal errors resolved and CSVs regenerated.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vVFG1nmD1VVv","executionInfo":{"status":"ok","timestamp":1763098127793,"user_tz":480,"elapsed":1611,"user":{"displayName":"Maya Patel","userId":"14782061383850637760"}},"outputId":"6dc85a5d-8fbe-4819-b6c9-7865a5d0d5ff"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["SUCCESS: All temporal errors resolved and CSVs regenerated.\n"]}]},{"cell_type":"markdown","source":["**4) Checkpoint 4 Completion**\n","\n","All required CSV files for the relational database schema have been generated and saved to Google Drive folder:\n","* `addresses.csv`\n","* `offices.csv`\n","* `users.csv`\n","* `agents.csv`\n","* `clients.csv`\n","* `client_preferences.csv`\n","* `properties.csv`\n","* `listings.csv`\n","* `appointments.csv`\n","* `offers.csv`\n","* `transactions.csv`\n","* `marketing_campaigns.csv`\n"],"metadata":{"id":"nguVP7jDwliE"}}]}